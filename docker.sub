universe 		= docker
docker_image        = pytorch/pytorch:1.13.0-cuda11.6-cudnn8-runtime
executable              = executable_cmd.sh
output                  = exp/$(ClusterId).$(ProcId).out
error                   = exp/$(ClusterId).$(ProcId).err
log                     = exp/$(ClusterId).log
should_transfer_files   = YES
when_to_transfer_output = ON_EXIT_OR_EVICT
transfer_input_files =  config, dataset, model, trainer, utils, init_config.py, eval.py, executable_cmd.sh, run.py, so_run.py, self_dist_run.py
transfer_output_files = .
request_GPUs = 1
request_CPUs = 4
request_memory = 64G
requirements = (UidDomain == "cs.uni-saarland.de") \
                && (GPUs_Capability > 5.5) \
                && (GPUs_GlobalMemoryMb >= 48000)
+WantGPUHomeMounted = true
queue 1

#docker_image 		= pytorch/pytorch:1.12.1-cuda11.3-cudnn8-runtime
#PREEMPTION_REQUIREMENTS = false
#                && (CUDAGlobalMemoryMb >= 1000)

#request_disk = 64G
#requirements = CUDARuntimeVersion >= 5.5 \
#    && (CUDACapability >= 3.0) \

# source /home/nipa00002/miniconda3/bin/activate
# conda activate light
# condor_submit -i
# condor_status
# condor_q -better
# condor_rm